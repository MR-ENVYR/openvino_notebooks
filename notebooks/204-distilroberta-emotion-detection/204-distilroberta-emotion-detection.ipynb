{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11f1573-3d77-4d1a-abfb-f5445dba07c6",
   "metadata": {},
   "source": [
    "# Convert and Optimize DistilRoBERTa with OpenVINOâ„¢\n",
    "\n",
    "Transformers are a set of popular architectures used in Natural Language Processing (NLP). They've literally transformed the NLP domain by becoming one of the most widely used architectures ever since their introduction in the paper - [\"Attention is all you need\"](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "Bidirectional Encoder Representations Transformer or more commonly known as [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) is an open source transformer, widely used in NLP by fine tuning it to particular tasks. The uniqueness of BERT is that it is deeply bidirectional. This means that BERT processes text bidirectionally, i.e, it takes into account, both the left and right sides of the token. \n",
    "\n",
    "[RoBERTa - Robustly Optimized BERT pretraining Approach](https://arxiv.org/abs/1907.11692) published in 2018 introduced an optimized approach to pre-train BERT like language models. It used the same architecture as BERT but modified key hyperparameters and other training parameters. The application of [Knowledge Distillation](https://en.wikipedia.org/wiki/Knowledge_distillation) to transformer models led to the widespread adaptation of distilled models as these models are much more faster, smaller and efficient to run on common computers. [DistilRoBERTa](https://huggingface.co/distilroberta-base) and [DistilBERT](https://arxiv.org/abs/1910.01108) are two such models which use knowledge distillation to reduce model size and significantly improve performance.\n",
    "\n",
    "Transformer architectures play a vital role in text analysis. Furthermore, distilled models make it possible to run transfomers on devices which don't have huge computational power. \n",
    "\n",
    "Although these models are written using different Deep Learning frameworks such as PyTorch and Tensorflow, they are more populary used through the [Transformer's library](https://huggingface.co/docs/transformers/index) built by [Hugging Face](https://huggingface.co).\n",
    "\n",
    "This tutorial will use [Emotion Classification in English](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base), which is a fine-tuned checkpoint of [DistilRoBERTa-base](https://huggingface.co/distilroberta-base). The tutorial will provide step-by-step instructions on how to convert and optimize the transformer model using OpenVINO toolkit developed by Intel AI.\n",
    "\n",
    "The following image gives a brief overview of the steps followed in the tutorial:\n",
    "![204-flowchart-convert-optimize](./204-flow.jpg)\n",
    "\n",
    "The tutorial consists of the following sections:\n",
    "- [Installations and imports](#Installations-and-imports)\n",
    "- [Setting up dataset](#Download-and-setup-dataset-for-the-notebook)\n",
    "- [Validating original model](#Fetch-and-validate-original-model)\n",
    "- [Converting model to OpenVINO IR](#Converting-transformer-model-to-OpenVINO-Model-(IR))\n",
    "- [Optimizing the model](#Prepare-and-run-Optimization-(Quantization)-pipeline) (Under Construction)\n",
    "- [Deleting created directories](#Deleting-created-directories-and-files-(Optional))\n",
    "- [References](#References)\n",
    "\n",
    ">**Note:** The code blocks in the Installation and imports section install and import all the libraries required to run the notebook. The commented imports in the code blocks of subsequent sections are provided to show where and how a particular import is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fabbec-2ead-452e-a189-d1e6b72fba08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5981a0-0ed1-4f51-a186-7d2bb6a0b178",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install optimum[openvino,nncf]==1.7.3\n",
    "!pip install datasets==2.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23286488-b2f7-46d8-b613-67efb8395362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports used in the notebook\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import json\n",
    "import time\n",
    "from shutil import rmtree, unpack_archive\n",
    "\n",
    "import nncf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from notebook_utils import download_file\n",
    "from optimum.intel import OVModelForSequenceClassification as OVModel\n",
    "from optimum.intel.openvino import OVConfig, OVQuantizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification as AutoModel\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb76f2-bc3f-455f-aafc-f5348713638e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download and setup dataset for the notebook\n",
    "\n",
    "DistilRoBERTa-base was fine-tuned on multiple datasets for emotion classification as mentioned [here](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base#appendix-%F0%9F%93%9A). We will use the EmotionLines Dataset ([Paper](https://arxiv.org/abs/1802.08379)) which can be found [here](https://doraemon.iis.sinica.edu.tw/emotionlines/download.html). It contains dialogues from Friends TV Scripts and each dialogue is labelled as one of six Ekman's basic emotions plus the neutral emotion.\n",
    "\n",
    "The following code downloads and extracts the dataset into the `data` folder. The code block after that reads the dataset from `friends_test.json` file and stores it in `test_data` dataframe. Note that we only store the `utterances` and `emotion` column which are the text and the corresponding true prediction respectively. We will be using this dataset throughout the notebook to make comparisons.\n",
    "\n",
    ">**Note:** Run the code blocks in this section before performing classification in subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dea1f5-733f-46e6-8438-67acb617ded0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downloading EmotionLines Dataset and extracting files\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# sys.path.append(\"../utils\")\n",
    "# from shutil import unpack_archive\n",
    "# from notebook_utils import download_file\n",
    "\n",
    "DATASET_URL = \"https://drive.google.com/uc?export=download&id=1Koxs2pVSmmO_-LWDGx3uUODVHY1yNrTM\"\n",
    "DATA_DIR = Path(\"data/\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "filepath = download_file(\n",
    "    DATASET_URL, directory=DATA_DIR, filename=\"EML_DATA.tar.gz\", show_progress=True\n",
    ")\n",
    "\n",
    "if not (DATA_DIR / \"EmotionLines/Friends\").exists():\n",
    "    unpack_archive(filepath, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90f8c9-192a-4344-9e9f-09287b88dcda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parsing JSON data and reading to DataFrame\n",
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "TEST_DATA_PATH = Path(\"data/EmotionLines/Friends/friends_test.json\")\n",
    "\n",
    "# Reads json into list of list of dicts\n",
    "with open(TEST_DATA_PATH, \"r\") as test_file:\n",
    "    test_jsons = json.load(test_file)\n",
    "\n",
    "# Flattening data into single list of dicts\n",
    "test_dictlist = []\n",
    "for dictlist in test_jsons:\n",
    "    test_dictlist.extend(dictlist)\n",
    "\n",
    "# Creating test_data DataFrame\n",
    "test_data = pd.DataFrame(test_dictlist).drop([\"speaker\", \"annotation\"], axis=1)\n",
    "DATA_SAVE_PATH = Path(\"data/test_data.csv\")\n",
    "test_data.to_csv(DATA_SAVE_PATH)\n",
    "\n",
    "# Taking 10 samples as subset\n",
    "test_subset = test_data.head(10)\n",
    "test_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72d4e3-901e-4761-a881-ea1f906564fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetch and validate original model\n",
    "We will use a small subset of `test_data` to check how the model performs inference. Additionally this section would describe how to use a transformer model from the [Transformer's library](https://huggingface.co/docs/transformers/index) provided by [Hugging Face](https://huggingface.co). The same model would be used in upcoming sections too.\n",
    "\n",
    "Typical steps to use a pretrained transformer model from the transformers library:\n",
    "1. Import Model, Tokenizer and Pipeline from the library\n",
    "2. Load the pretrained Model and Tokenizer using the model's ID\n",
    "3. Define pipeline for classification\n",
    "\n",
    "The image below shows a basic pipeline used by transformers to perform text analysis:\n",
    "![204-flowchart-tokenize-predict](./204-predict.jpg)\n",
    "\n",
    "We will use the `infer` function defined below to perform inference. We can set `return_all_scores` to True in the infer function return scores for each emotion and store in the output DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009ec69-2275-4178-87d2-19fc77f9f588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining infer function and importing tokenizer, pipeline\n",
    "# import pandas as pd\n",
    "# from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "def infer(\n",
    "    model,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    test_dataset: pd.DataFrame,\n",
    "    inp_text_col: str,\n",
    "    pred_col: str = \"predicted_emotion\",\n",
    "    return_all_scores: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generic inference function to take a DataFrame containing texts and return new DataFrame with predicted emotion for each text sample along with annotated emotion and optionally scores for each emotion.\n",
    "    Parameters:\n",
    "        model: OpenVINO compiled model\n",
    "        tokenizer (AutoTokenizer): Tokenizer for text\n",
    "        test_dataset (DataFrame): Dataset for testing\n",
    "        inp_text_col (str): Column name containing input sequences\n",
    "        pred_col (str, *optional*, \"predicted_emotion\"): Column to store predictions in\n",
    "        return_all_scores (bool, *optional* ,False): Return scores for each emotion\n",
    "    Returns:\n",
    "        test_predictions (DataFrame): predictions and true labels alongside inputs\n",
    "    \"\"\"\n",
    "\n",
    "    if test_dataset.empty:\n",
    "        raise ValueError(\"Empty DataFrame provided at input\")\n",
    "\n",
    "    if not inp_text_col in test_dataset.columns:\n",
    "        raise KeyError(f\"Invalid column name provided - {inp_text_col}\")\n",
    "\n",
    "    test_predicted = test_dataset.copy()\n",
    "    predicted_emotion = []\n",
    "    emotion_score = []\n",
    "    classifier_pipeline = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_all_scores=return_all_scores,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        if return_all_scores is True:\n",
    "            for text in test_predicted[inp_text_col]:\n",
    "                prediction = classifier_pipeline(text)\n",
    "                prediction_scores = classifier_pipeline(text)\n",
    "                prediction_df = pd.DataFrame(prediction_scores[0])\n",
    "                labels = prediction_df[\"label\"]\n",
    "                scores = prediction_df[\"score\"]\n",
    "                prediction = labels[np.argmax(scores)]\n",
    "                predicted_emotion.append(prediction)\n",
    "                all_scores = dict(zip(labels, scores))\n",
    "                emotion_score.append(all_scores)\n",
    "\n",
    "            emotion_score = pd.DataFrame(emotion_score)\n",
    "            test_predicted[[pred_col]] = predicted_emotion\n",
    "            test_predicted = pd.concat([test_subset, emotion_score], axis=1)\n",
    "\n",
    "        else:\n",
    "            for text in test_predicted[inp_text_col]:\n",
    "                prediction = classifier_pipeline(text)[0]\n",
    "                predicted_emotion.append(prediction[\"label\"])\n",
    "                emotion_score.append(prediction[\"score\"])\n",
    "            test_predicted[pred_col] = predicted_emotion\n",
    "            test_predicted[\"emotion_score\"] = emotion_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Inference failed with exception - {e}\")\n",
    "    return test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cebe83-bb9b-490f-b566-0d4d1d3ec8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "# from transformers import AutoModelForSequenceClassification as AutoModel\n",
    "\n",
    "MODEL_ID = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "Model = AutoModel.from_pretrained(MODEL_ID)\n",
    "Tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4c764-15b3-42c9-94ce-bad5706f8184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performing classification on subset of test_data\n",
    "model_predictions = infer(\n",
    "    model=Model,\n",
    "    tokenizer=Tokenizer,\n",
    "    test_dataset=test_subset,\n",
    "    inp_text_col=\"utterance\",\n",
    "    return_all_scores=False,\n",
    ")\n",
    "model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cf8f0-4c88-4ed8-9856-e9520c946411",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting transformer model to OpenVINO Model (IR)\n",
    "Since the creators of transformers library provide [Optimum Library](https://huggingface.co/docs/optimum/index) which is an extension to the transformer's libary for exporting  of pretrained models, we don't have to write extra code for it. Optimum provides an API to directly export transformer models to ONNX, OpenVINO IR, etc. For more details on OpenVINO IR, refer this [link](https://docs.openvino.ai/latest/openvino_docs_MO_DG_IR_and_opsets.html). \n",
    "\n",
    "The last lines of the below code block are used to save the OpenVINO model files into the `model` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9618859-5353-4de5-af31-d672f63b3c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "# from optimum.intel import OVModelForSequenceClassification as OVModel\n",
    "\n",
    "MODEL_ID = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "OVModel = OVModel.from_pretrained(MODEL_ID, export=True)\n",
    "Tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Saving OpenVINO model files\n",
    "MODEL_DIR = Path(\"model/\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "OVModel.save_pretrained(MODEL_DIR)\n",
    "Tokenizer.save_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c719d3e-1045-4302-aa8f-4f5e7e02ea31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performing classification on subset of test_data\n",
    "OVmodel_predictions = infer(\n",
    "    model=OVModel,\n",
    "    tokenizer=Tokenizer,\n",
    "    test_dataset=test_subset,\n",
    "    inp_text_col=\"utterance\",\n",
    "    return_all_scores=False,\n",
    ")\n",
    "OVmodel_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96dd0a-e213-46c9-86f2-62520a7bcf69",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare and run Optimization (Quantization) pipeline\n",
    "\n",
    "After obtaining the OpenVINO IR Model in the [previous section](#Fetch-and-validate-original-model), we can optimize the model through quantization. Quantization basically involves using lower precision representation instead of higher precision representation (usually 32 bit floating point). This reduces memory requirements, energy consumption (theoretically), and speeds up inference by faster matrix multiplications and other arithmetic operations. Quantization helps to make models more efficient with negligible reduction in prediction performance while significantly reducing computing requirements. For a detailed understanding of quantization, refer this [paper](https://arxiv.org/pdf/1712.05877.pdf).\n",
    "\n",
    "We have two ways to quantize the OpenVINO IR model obtained before.\n",
    "- Using [OpenVINO's API for Quantization](https://docs.openvino.ai/latest/ptq_introduction.html)\n",
    "- Using [Optimum's API for Transformer Quantization](https://huggingface.co/docs/optimum/intel/optimization_ov)\n",
    "\n",
    "The following subsections describe how to use both the methods mentioned above.\n",
    "Since Optimum's API uses NNCF as a backend to perform quantization, we will use that to show how to perform quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a6073-2e4e-4b16-a1be-e12b8f621f77",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining testing function and reporting pre-optimization metrics\n",
    "Before we get started with quantization, we define a testing function to report accuracies and inference times on the entire dataset downloaded [previously](#Download-and-setup-dataset-for-the-notebook). We also report the accuracy and inference time of the OpenVINO IR model in this subsection for comparison. To keep things simple, we will report and analyse four [standard classification metrics](https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd) which are Accuracy, Precision, Recall and F1-Score using [Scikit-learn's metrics module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). The metrics are summarized below.\n",
    "\n",
    "1. `Accuracy`: Accuracy is the ratio of correctly classified samples and total number of samples in the dataset\n",
    "2. `Precision`: Precision tells us how precisely the model predicts, i.e, out of all the samples predicted as positive, how many are actually positive.\n",
    "3. `Recall`: Recall describes how well the model recalls patterns, i.e, how many of true positives are correctly identified by the model.\n",
    "4. `F1-Score`: This is the [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean) of Precision and Recall. It helps to minimize both False positives and False Negatives by bringing a balance between the precision-recall trade-off. \n",
    "\n",
    "We also define a `tester` function to print metrics and report inference time in an orderly fashion. Putting `plotcm=True` in the tester function would plot the confusion matrix which can be used for further analysis.\n",
    ">**Note 1**: Please run the code block where `infer` function is defined to ensure the below block runs without errors (see [this](#Fetch-and-validate-original-model) section).\n",
    "\n",
    ">**Note 2**: Please run the code block where data is setup to ensure the successive blocks run without errors (see [this](#Download-and-setup-dataset-for-the-notebook) section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99efcd-9ccc-4a2d-bf31-37b00a6fe188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining function to generate classification metrics\n",
    "# import time\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def clmetrics(y_true: list, y_pred: list, plotcm: bool = False) -> tuple:\n",
    "    \"\"\"\n",
    "    Generic function to generate four standard classification metrics viz. Accuracy, Precision, Recall, F1-Score using scikit-learn by taking true labels and predicted labels as input.\n",
    "    Parameters:\n",
    "        y_true (list, array-like): True labels\n",
    "        y_pred (list, array-like): Predicted labels\n",
    "        plotcm (bool, *optional*,False): Whether to plot confusion matrix\n",
    "    Returns:\n",
    "        clreport (str): Classification report containing metrics\n",
    "        cm (np.ndarray): Confusion Matrix\n",
    "        cmplot (ConfusionMatrixDisplay): Confusion Matrix object to plot confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking inputs\n",
    "    if len(y_true) < 1:\n",
    "        raise IndexError(\"Empty list received at input - y_true\")\n",
    "\n",
    "    if len(y_pred) < 1:\n",
    "        raise IndexError(\"Empty list received at input - y_pred\")\n",
    "\n",
    "    # Obtaining metrics using scikit-learn functions\n",
    "    try:\n",
    "        # Classification report - Accuracy, Precision, Recall, F1-Score\n",
    "        clreport = classification_report(y_true, y_pred)\n",
    "\n",
    "        # Plotting Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cmplot = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        if plotcm is True:\n",
    "            print(clreport)\n",
    "            cmplot.plot()\n",
    "            plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Metric generation failed with exception - {e}\")\n",
    "    return clreport, cm, cmplot\n",
    "\n",
    "\n",
    "# Defining function to record times and report metrics\n",
    "def tester(\n",
    "    model,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    test_dataset: pd.DataFrame,\n",
    "    inp_text_col: str,\n",
    "    true_label_col: str,\n",
    "    pred_col: str = \"predicted_emotion\",\n",
    "    model_name: str = \"\",\n",
    "    return_all_scores: bool = False,\n",
    "    plotcm: bool = False,\n",
    "    use_compile: bool = True,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Tester function which uses infer and clmetrics function to test model and report inference time and metrics on provided dataset.\n",
    "    Parameters:\n",
    "        model: OpenVINO model. Must not be compiled. Set compile=False when loading model.\n",
    "        tokenizer (AutoTokenizer): Tokenizer for text\n",
    "        test_dataset (DataFrame): Dataset for testing\n",
    "        inp_text_col (str): Column name containing input sequences\n",
    "        true_label_col (str): Column name containing true predictions\n",
    "        pred_col (str, *optional*, \"predicted_emotion\"): Column to store predictions in\n",
    "        model_name (str, *optional*, \"\"): Model name - used to print with metrics for identification\n",
    "        return_all_scores (bool, *optional* ,False): Return scores for each emotion\n",
    "        plotcm (bool, *optional*,False): Whether to plot confusion matrix\n",
    "        use_compile (bool, True): Whether to compile model before performing inference\n",
    "    Returns:\n",
    "        test_predictions (pd.DataFrame): DataFrame containing predictions and scores for inputs\n",
    "        metrics (tuple): Tuple containing classification report, confusion matrix and plot of confusion matrix in that order\n",
    "        infer_time (str): Time taken to perform inference over dataset (H:M:S)\n",
    "    \"\"\"\n",
    "    # Compiling model if needed\n",
    "    if use_compile is True:\n",
    "        model.compile()\n",
    "    additional_prints = \"\".join([\"=\"] * 20)  # Just some beautification\n",
    "\n",
    "    # Inference using infer\n",
    "    print(f\"{additional_prints} Model inference started {additional_prints}\")\n",
    "    infer_start = time.time()\n",
    "    test_predictions = infer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        test_dataset=test_dataset,\n",
    "        inp_text_col=inp_text_col,\n",
    "        pred_col=pred_col,\n",
    "        return_all_scores=return_all_scores,\n",
    "    )\n",
    "    infer_end = time.time()\n",
    "    infer_time = time.strftime(\"%H:%M:%S\", time.gmtime(infer_end - infer_start))\n",
    "    print(f\"{additional_prints} Model inference finished in {infer_time} {additional_prints}\")\n",
    "\n",
    "    # Obtaining true labels and predictions\n",
    "    y_true = test_dataset[true_label_col]\n",
    "    y_pred = test_predictions[pred_col]\n",
    "\n",
    "    # Generating and printing metrics using clmetrics\n",
    "    print(f\"{additional_prints} Metrics of {model_name} Model {additional_prints}\")\n",
    "    metrics = clmetrics(y_true=y_true, y_pred=y_pred, plotcm=plotcm)\n",
    "    clreport, cm, cmplot = metrics[0], metrics[1], metrics[2]\n",
    "    print(clreport)\n",
    "    print(f\"{additional_prints*3}\")\n",
    "\n",
    "    return test_predictions, metrics, infer_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549b852-927a-4212-b859-f94c4649e109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating metrics using test_data for OpenVINO IR\n",
    "Model_testout = tester(\n",
    "    model=Model,\n",
    "    model_name=\"Pretrained\",\n",
    "    tokenizer=Tokenizer,\n",
    "    test_dataset=test_data,\n",
    "    inp_text_col=\"utterance\",\n",
    "    true_label_col=\"emotion\",\n",
    "    return_all_scores=False,\n",
    "    use_compile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1891a9-4c47-4435-b951-bff6fcece512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating metrics using test_data for OpenVINO IR\n",
    "OVmodel_testout = tester(\n",
    "    model=OVModel,\n",
    "    model_name=\"OpenVINO IR\",\n",
    "    tokenizer=Tokenizer,\n",
    "    test_dataset=test_data,\n",
    "    inp_text_col=\"utterance\",\n",
    "    true_label_col=\"emotion\",\n",
    "    return_all_scores=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc56d2-3a3f-4128-8495-d42f71a53088",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deleting created directories and files (Optional)\n",
    "The following codeblock deletes all the directories and files that were created after running this notebook. To run it, please uncomment the code first.\n",
    "\n",
    ">**Note**: Please ensure you haven't stored any important files in the directories created with this notebook. Use the following code block with <u>extreme caution</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b6ba8-e6a3-43b0-9b97-97030440d5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from shutil import rmtree\n",
    "# rmtree(DATA_DIR)\n",
    "# rmtree(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b819f-083a-4129-864e-5ae75f99444d",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a012f5-52f9-4f51-affc-880a516f2a66",
   "metadata": {},
   "source": [
    "\\[1\\] [Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017).](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "\\[2\\] [Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018).\n",
    "](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "\\[3\\] [Liu, Yinhan, et al. \"Roberta: A robustly optimized bert pretraining approach.\" arXiv preprint arXiv:1907.11692 (2019).](https://arxiv.org/abs/1907.11692)\n",
    "\n",
    "\\[4\\] [Sanh, Victor, et al. \"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.\" arXiv preprint arXiv:1910.01108 (2019).](https://arxiv.org/abs/1910.01108)\n",
    "\n",
    "\\[5\\] [Jochen Hartmann, \"Emotion English DistilRoBERTa-base\", 2022.](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
